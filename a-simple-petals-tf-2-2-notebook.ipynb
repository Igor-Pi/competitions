{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fae55ed",
   "metadata": {
    "papermill": {
     "duration": 0.017365,
     "end_time": "2022-12-12T06:45:24.215874",
     "exception": false,
     "start_time": "2022-12-12T06:45:24.198509",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# A Simple TF 2.2 notebook\n",
    "\n",
    "This is intended as a simple, short introduction to the operations competitors will need to perform with TPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c41f6e4",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-12-12T06:45:24.259596Z",
     "iopub.status.busy": "2022-12-12T06:45:24.258855Z",
     "iopub.status.idle": "2022-12-12T06:45:30.900198Z",
     "shell.execute_reply": "2022-12-12T06:45:30.900721Z",
     "shell.execute_reply.started": "2022-12-12T05:27:52.550854Z"
    },
    "papermill": {
     "duration": 6.669105,
     "end_time": "2022-12-12T06:45:30.901107",
     "exception": false,
     "start_time": "2022-12-12T06:45:24.232002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 06:45:25.061766: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n",
      "2022-12-12 06:45:25.061893: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.4.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from kaggle_datasets import KaggleDatasets\n",
    "import numpy as np\n",
    "\n",
    "print(\"Tensorflow version \" + tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a75e378",
   "metadata": {
    "papermill": {
     "duration": 0.015796,
     "end_time": "2022-12-12T06:45:30.934371",
     "exception": false,
     "start_time": "2022-12-12T06:45:30.918575",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Detect my accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0df6dffe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T06:45:30.973983Z",
     "iopub.status.busy": "2022-12-12T06:45:30.970295Z",
     "iopub.status.idle": "2022-12-12T06:45:37.453236Z",
     "shell.execute_reply": "2022-12-12T06:45:37.453729Z",
     "shell.execute_reply.started": "2022-12-12T05:27:59.501973Z"
    },
    "papermill": {
     "duration": 6.502741,
     "end_time": "2022-12-12T06:45:37.453938",
     "exception": false,
     "start_time": "2022-12-12T06:45:30.951197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on TPU  grpc://10.0.0.2:8470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 06:45:30.977417: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-12-12 06:45:30.980476: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n",
      "2022-12-12 06:45:30.980522: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-12-12 06:45:30.980556: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (c2d72b5537a9): /proc/driver/nvidia/version does not exist\n",
      "2022-12-12 06:45:30.983786: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-12 06:45:30.985528: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-12-12 06:45:31.020010: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.0.2:8470}\n",
      "2022-12-12 06:45:31.020088: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:30019}\n",
      "2022-12-12 06:45:31.046507: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.0.2:8470}\n",
      "2022-12-12 06:45:31.046565: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:30019}\n",
      "2022-12-12 06:45:31.048218: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:411] Started server with target: grpc://localhost:30019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPLICAS:  8\n"
     ]
    }
   ],
   "source": [
    "# Detect hardware, return appropriate distribution strategy\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df94f37c",
   "metadata": {
    "papermill": {
     "duration": 0.01674,
     "end_time": "2022-12-12T06:45:37.487684",
     "exception": false,
     "start_time": "2022-12-12T06:45:37.470944",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Get my data path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "835c4aed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T06:45:37.535383Z",
     "iopub.status.busy": "2022-12-12T06:45:37.534650Z",
     "iopub.status.idle": "2022-12-12T06:45:37.946483Z",
     "shell.execute_reply": "2022-12-12T06:45:37.945794Z",
     "shell.execute_reply.started": "2022-12-12T05:28:05.974206Z"
    },
    "papermill": {
     "duration": 0.441568,
     "end_time": "2022-12-12T06:45:37.946651",
     "exception": false,
     "start_time": "2022-12-12T06:45:37.505083",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "GCS_DS_PATH = KaggleDatasets().get_gcs_path() # you can list the bucket with \"!gsutil ls $GCS_DS_PATH\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6daad8",
   "metadata": {
    "papermill": {
     "duration": 0.016596,
     "end_time": "2022-12-12T06:45:37.980666",
     "exception": false,
     "start_time": "2022-12-12T06:45:37.964070",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Set some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49cf0e6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T06:45:38.023020Z",
     "iopub.status.busy": "2022-12-12T06:45:38.022250Z",
     "iopub.status.idle": "2022-12-12T06:45:38.025889Z",
     "shell.execute_reply": "2022-12-12T06:45:38.025347Z",
     "shell.execute_reply.started": "2022-12-12T05:28:06.346396Z"
    },
    "papermill": {
     "duration": 0.026664,
     "end_time": "2022-12-12T06:45:38.026046",
     "exception": false,
     "start_time": "2022-12-12T06:45:37.999382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = [512, 512] # at this size, a GPU will run out of memory. Use the TPU\n",
    "EPOCHS = 25\n",
    "BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n",
    "\n",
    "NUM_TRAINING_IMAGES = 12753*2\n",
    "NUM_TEST_IMAGES = 7382\n",
    "STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bdd350",
   "metadata": {
    "papermill": {
     "duration": 0.016586,
     "end_time": "2022-12-12T06:45:38.059842",
     "exception": false,
     "start_time": "2022-12-12T06:45:38.043256",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load my data\n",
    "\n",
    "This data is loaded from Kaggle and automatically sharded to maximize parallelization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0365a2ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T06:45:38.121398Z",
     "iopub.status.busy": "2022-12-12T06:45:38.113452Z",
     "iopub.status.idle": "2022-12-12T06:45:38.958009Z",
     "shell.execute_reply": "2022-12-12T06:45:38.957413Z",
     "shell.execute_reply.started": "2022-12-12T05:28:06.353413Z"
    },
    "papermill": {
     "duration": 0.881234,
     "end_time": "2022-12-12T06:45:38.958161",
     "exception": false,
     "start_time": "2022-12-12T06:45:38.076927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 06:45:38.181974: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-12-12 06:45:38.564688: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-12-12 06:45:38.838302: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n"
     ]
    }
   ],
   "source": [
    "# with augmentation\n",
    "\n",
    "def decode_image(image_data, augmentation = False):\n",
    "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
    "    image = tf.cast(image, tf.float32) / 255.0  # convert image to floats in [0, 1] range\n",
    "    #image = tf.cast(image, tf.float32) / 127.5 - 1  # convert image to floats in [-1, 1] range (for Xception)\n",
    "    image = tf.reshape(image, [*IMAGE_SIZE, 3]) # explicit size needed for TPU\n",
    "    if augmentation:\n",
    "        image = tf.image.random_flip_left_right(image)\n",
    "        image = tf.image.random_contrast(image, 0.7, 1.5)\n",
    "        image = tf.image.random_brightness(image, 0.3)\n",
    "        image = tf.image.rot90(image, np.random.randint(1,4))\n",
    "    \n",
    "    return image\n",
    "\n",
    "def read_labeled_tfrecord(example):\n",
    "    LABELED_TFREC_FORMAT = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n",
    "        \"class\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n",
    "    image = decode_image(example['image'])\n",
    "    label = tf.cast(example['class'], tf.int32)\n",
    "    return image, label # returns a dataset of (image, label) pairs\n",
    "\n",
    "def read_labeled_tfrecord_wa(example):\n",
    "    LABELED_TFREC_FORMAT = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n",
    "        \"class\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n",
    "    image = decode_image(example['image'], augmentation=True)\n",
    "    label = tf.cast(example['class'], tf.int32)\n",
    "    return image, label # returns a dataset of (image, label) pairs\n",
    "\n",
    "def read_unlabeled_tfrecord(example):\n",
    "    UNLABELED_TFREC_FORMAT = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n",
    "        \"id\": tf.io.FixedLenFeature([], tf.string),  # shape [] means single element\n",
    "        # class is missing, this competitions's challenge is to predict flower classes for the test dataset\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n",
    "    image = decode_image(example['image'])\n",
    "    idnum = example['id']\n",
    "    return image, idnum # returns a dataset of image(s)\n",
    "\n",
    "def load_dataset(filenames, labeled=True, ordered=False, augmentation=False):\n",
    "    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n",
    "    # disregarding data order. Order does not matter since we will be shuffling the data anyway.\n",
    "\n",
    "    ignore_order = tf.data.Options()\n",
    "    if not ordered:\n",
    "        ignore_order.experimental_deterministic = False # disable order, increase speed\n",
    "\n",
    "    dataset = tf.data.TFRecordDataset(filenames) # automatically interleaves reads from multiple files\n",
    "    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n",
    "    dataset = dataset.map(read_unlabeled_tfrecord if not labeled \n",
    "                          else read_labeled_tfrecord_wa if augmentation else read_labeled_tfrecord)\n",
    "#     dataset = dataset.map(read_labeled_tfrecord if labeled else read_unlabeled_tfrecord)\n",
    "    # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\n",
    "    return dataset\n",
    "\n",
    "@tf.function\n",
    "def get_training_dataset(augmentation=False):\n",
    "    dataset = load_dataset(tf.io.gfile.glob(GCS_DS_PATH + '/tfrecords-jpeg-{}x{}/train/*.tfrec'.format(*IMAGE_SIZE)), \n",
    "                           labeled=True, augmentation=augmentation)\n",
    "    dataset = dataset.repeat() # the training dataset must repeat for several epochs\n",
    "    dataset = dataset.shuffle(2048)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    return dataset\n",
    "\n",
    "def get_validation_dataset():\n",
    "    dataset = load_dataset(tf.io.gfile.glob(GCS_DS_PATH + '/tfrecords-jpeg-{}x{}/val/*.tfrec'.format(*IMAGE_SIZE)), \n",
    "                           labeled=True, ordered=False)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.cache()\n",
    "    return dataset\n",
    "\n",
    "def get_test_dataset(ordered=False):\n",
    "    dataset = load_dataset(tf.io.gfile.glob(GCS_DS_PATH + '/tfrecords-jpeg-{}x{}/test/*.tfrec'.format(*IMAGE_SIZE)), \n",
    "                           labeled=False, ordered=ordered)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    return dataset\n",
    "\n",
    "training_dataset = get_training_dataset()\n",
    "augmented_dataset = get_training_dataset(augmentation=True)\n",
    "# augmented_dataset_1 = get_training_dataset(augmentation=True)\n",
    "validation_dataset = get_validation_dataset()\n",
    "train_aug_ds = training_dataset.concatenate(augmented_dataset)\n",
    "# train_aug_ds = train_aug_ds.concatenate(augmented_dataset_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b601f39b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T06:45:38.998958Z",
     "iopub.status.busy": "2022-12-12T06:45:38.998090Z",
     "iopub.status.idle": "2022-12-12T06:45:39.000776Z",
     "shell.execute_reply": "2022-12-12T06:45:39.001405Z",
     "shell.execute_reply.started": "2022-12-12T05:28:07.193292Z"
    },
    "papermill": {
     "duration": 0.025528,
     "end_time": "2022-12-12T06:45:39.001587",
     "exception": false,
     "start_time": "2022-12-12T06:45:38.976059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# for i, (image, label) in enumerate(augmented_dataset.take(9)):\n",
    "#     ax = plt.subplot(3, 3, i + 1)\n",
    "#     plt.imshow(image[0])\n",
    "#     plt.title(int(label[0]))\n",
    "#     plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4631caf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T06:45:39.046411Z",
     "iopub.status.busy": "2022-12-12T06:45:39.045473Z",
     "iopub.status.idle": "2022-12-12T06:45:39.050041Z",
     "shell.execute_reply": "2022-12-12T06:45:39.050727Z",
     "shell.execute_reply.started": "2022-12-12T05:28:07.199587Z"
    },
    "papermill": {
     "duration": 0.028938,
     "end_time": "2022-12-12T06:45:39.050910",
     "exception": false,
     "start_time": "2022-12-12T06:45:39.021972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for tf version above 2.5\n",
    "#data_augmentation = tf.keras.Sequential(\n",
    "#    [tf.keras.layers.RandomFlip(), \n",
    "#     tf.keras.layers.RandomRotation(0.3),\n",
    "#     tf.keras.layers.RandomContrast(0.3)]\n",
    "#)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "462adff6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T06:45:39.091250Z",
     "iopub.status.busy": "2022-12-12T06:45:39.090578Z",
     "iopub.status.idle": "2022-12-12T06:45:39.094706Z",
     "shell.execute_reply": "2022-12-12T06:45:39.095308Z",
     "shell.execute_reply.started": "2022-12-12T05:28:07.211862Z"
    },
    "papermill": {
     "duration": 0.025667,
     "end_time": "2022-12-12T06:45:39.095485",
     "exception": false,
     "start_time": "2022-12-12T06:45:39.069818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#for images, labels in training_dataset.take(1):\n",
    "#    plt.figure(figsize=(10, 10))\n",
    "#    first_image = images[0]\n",
    "#    for i in range(9):\n",
    "#        ax = plt.subplot(3, 3, i + 1)\n",
    "#        augmented_image = data_augmentation(\n",
    "#            first_image, training=True\n",
    "#        )\n",
    "#        plt.imshow((augmented_image.numpy()*255).astype('int32'))\n",
    "#        plt.title(int(labels[0]))\n",
    "#        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4edc37",
   "metadata": {
    "papermill": {
     "duration": 0.017699,
     "end_time": "2022-12-12T06:45:39.131401",
     "exception": false,
     "start_time": "2022-12-12T06:45:39.113702",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Build a model on TPU (or GPU, or CPU...) with Tensorflow 2.1!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98f3c364",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T06:45:39.171609Z",
     "iopub.status.busy": "2022-12-12T06:45:39.170911Z",
     "iopub.status.idle": "2022-12-12T07:19:23.826534Z",
     "shell.execute_reply": "2022-12-12T07:19:23.827132Z",
     "shell.execute_reply.started": "2022-12-12T06:19:11.082343Z"
    },
    "papermill": {
     "duration": 2024.677932,
     "end_time": "2022-12-12T07:19:23.827322",
     "exception": false,
     "start_time": "2022-12-12T06:45:39.149390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "74842112/74836368 [==============================] - 0s 0us/step\n",
      "Epoch 1/15\n",
      "199/199 [==============================] - 216s 873ms/step - loss: 3.3705 - sparse_categorical_accuracy: 0.2685 - val_loss: 1.7320 - val_sparse_categorical_accuracy: 0.6630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 06:49:55.627189: W ./tensorflow/core/distributed_runtime/eager/destroy_tensor_handle_node.h:57] Ignoring an error encountered when deleting remote tensors handles: Invalid argument: Unable to find the relevant tensor remote_handle: Op ID: 62520, Output num: 0\n",
      "Additional GRPC error information from remote target /job:worker/replica:0/task:0:\n",
      ":{\"created\":\"@1670827795.623832118\",\"description\":\"Error received from peer ipv4:10.0.0.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Unable to find the relevant tensor remote_handle: Op ID: 62520, Output num: 0\",\"grpc_status\":3}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/15\n",
      "199/199 [==============================] - 124s 626ms/step - loss: 1.5303 - sparse_categorical_accuracy: 0.6859 - val_loss: 1.1785 - val_sparse_categorical_accuracy: 0.7651\n",
      "Epoch 3/15\n",
      "199/199 [==============================] - 125s 628ms/step - loss: 1.0557 - sparse_categorical_accuracy: 0.7806 - val_loss: 0.9503 - val_sparse_categorical_accuracy: 0.8025\n",
      "Epoch 4/15\n",
      "199/199 [==============================] - 125s 628ms/step - loss: 0.8436 - sparse_categorical_accuracy: 0.8236 - val_loss: 0.8289 - val_sparse_categorical_accuracy: 0.8211\n",
      "Epoch 5/15\n",
      "199/199 [==============================] - 126s 638ms/step - loss: 0.7038 - sparse_categorical_accuracy: 0.8476 - val_loss: 0.7475 - val_sparse_categorical_accuracy: 0.8370\n",
      "Epoch 6/15\n",
      "199/199 [==============================] - 127s 641ms/step - loss: 0.6155 - sparse_categorical_accuracy: 0.8657 - val_loss: 0.6934 - val_sparse_categorical_accuracy: 0.8508\n",
      "Epoch 7/15\n",
      "199/199 [==============================] - 127s 641ms/step - loss: 0.5513 - sparse_categorical_accuracy: 0.8821 - val_loss: 0.6521 - val_sparse_categorical_accuracy: 0.8570\n",
      "Epoch 8/15\n",
      "199/199 [==============================] - 127s 641ms/step - loss: 0.5013 - sparse_categorical_accuracy: 0.8937 - val_loss: 0.6205 - val_sparse_categorical_accuracy: 0.8621\n",
      "Epoch 9/15\n",
      "199/199 [==============================] - 128s 645ms/step - loss: 0.4643 - sparse_categorical_accuracy: 0.8963 - val_loss: 0.6047 - val_sparse_categorical_accuracy: 0.8634\n",
      "Epoch 10/15\n",
      "199/199 [==============================] - 126s 635ms/step - loss: 0.4295 - sparse_categorical_accuracy: 0.9042 - val_loss: 0.5780 - val_sparse_categorical_accuracy: 0.8677\n",
      "Epoch 11/15\n",
      "199/199 [==============================] - 125s 630ms/step - loss: 0.3986 - sparse_categorical_accuracy: 0.9109 - val_loss: 0.5662 - val_sparse_categorical_accuracy: 0.8685\n",
      "Epoch 12/15\n",
      "199/199 [==============================] - 125s 630ms/step - loss: 0.3688 - sparse_categorical_accuracy: 0.9162 - val_loss: 0.5517 - val_sparse_categorical_accuracy: 0.8766\n",
      "Epoch 13/15\n",
      "199/199 [==============================] - 128s 644ms/step - loss: 0.3527 - sparse_categorical_accuracy: 0.9206 - val_loss: 0.5370 - val_sparse_categorical_accuracy: 0.8790\n",
      "Epoch 14/15\n",
      "199/199 [==============================] - 126s 636ms/step - loss: 0.3358 - sparse_categorical_accuracy: 0.9251 - val_loss: 0.5305 - val_sparse_categorical_accuracy: 0.8742\n",
      "Epoch 15/15\n",
      "199/199 [==============================] - 128s 644ms/step - loss: 0.3238 - sparse_categorical_accuracy: 0.9263 - val_loss: 0.5227 - val_sparse_categorical_accuracy: 0.8772\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 15\n",
    "with strategy.scope():    \n",
    "    #pretrained_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False ,input_shape=[*IMAGE_SIZE, 3])\n",
    "    # - 0.68024 - pretrained_model = tf.keras.applications.InceptionV3(weights='imagenet', include_top=False ,input_shape=[*IMAGE_SIZE, 3])\n",
    "    # - 0.72673 - pretrained_model = tf.keras.applications.Xception(weights='imagenet', include_top=False ,input_shape=[*IMAGE_SIZE, 3])\n",
    "    # - 0.82843 - pretrained_model = tf.keras.applications.DenseNet201(weights='imagenet', include_top=False ,input_shape=[*IMAGE_SIZE, 3])\n",
    "    pretrained_model = tf.keras.applications.DenseNet201(weights='imagenet', include_top=False ,input_shape=[*IMAGE_SIZE, 3])\n",
    "    # pretrained_model = tf.keras.applications.Xception(weights='imagenet', include_top=False ,input_shape=[*IMAGE_SIZE, 3])\n",
    "    pretrained_model.trainable = False # tramsfer learning\n",
    "    \n",
    "    model = tf.keras.Sequential([\n",
    "        pretrained_model,\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "#         tf.keras.layers.Flatten(),\n",
    "#         tf.keras.layers.Dense(1024, activation='relu'),\n",
    "#         tf.keras.layers.Dropout(0.2),\n",
    "#         tf.keras.layers.Dense(512, activation='relu'),\n",
    "#         tf.keras.layers.Dropout(0.2),\n",
    "#         tf.keras.layers.Dense(256, activation='relu'),\n",
    "#         tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(104, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    #f1_score = tfa.metrics.F1Score(104, 'macro')\n",
    "        \n",
    "model.compile(\n",
    "#     optimizer='adam',\n",
    "    optimizer=tf.keras.optimizers.Nadam(),\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics=['sparse_categorical_accuracy']\n",
    ")\n",
    "\n",
    "historical = model.fit(train_aug_ds, \n",
    "          steps_per_epoch=STEPS_PER_EPOCH, \n",
    "          epochs=EPOCHS, \n",
    "          validation_data=validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6df2524",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T07:19:25.603176Z",
     "iopub.status.busy": "2022-12-12T07:19:25.597954Z",
     "iopub.status.idle": "2022-12-12T07:29:55.692908Z",
     "shell.execute_reply": "2022-12-12T07:29:55.693520Z",
     "shell.execute_reply.started": "2022-12-12T06:26:32.751445Z"
    },
    "papermill": {
     "duration": 630.988964,
     "end_time": "2022-12-12T07:29:55.693761",
     "exception": false,
     "start_time": "2022-12-12T07:19:24.704797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "199/199 [==============================] - 380s 730ms/step - loss: 1.3740 - sparse_categorical_accuracy: 0.7101 - val_loss: 5.3863 - val_sparse_categorical_accuracy: 0.5162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 07:25:46.468022: W ./tensorflow/core/distributed_runtime/eager/destroy_tensor_handle_node.h:57] Ignoring an error encountered when deleting remote tensors handles: Invalid argument: Unable to find the relevant tensor remote_handle: Op ID: 110046, Output num: 0\n",
      "Additional GRPC error information from remote target /job:worker/replica:0/task:0:\n",
      ":{\"created\":\"@1670829946.467932091\",\"description\":\"Error received from peer ipv4:10.0.0.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Unable to find the relevant tensor remote_handle: Op ID: 110046, Output num: 0\",\"grpc_status\":3}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3\n",
      "199/199 [==============================] - 125s 628ms/step - loss: 0.3487 - sparse_categorical_accuracy: 0.8989 - val_loss: 1.3748 - val_sparse_categorical_accuracy: 0.7802\n",
      "Epoch 3/3\n",
      "199/199 [==============================] - 124s 625ms/step - loss: 0.2194 - sparse_categorical_accuracy: 0.9358 - val_loss: 1.1425 - val_sparse_categorical_accuracy: 0.7955\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():    \n",
    "    pretrained_model.trainable = True # fine-tuning\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Nadam(),\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "EPOCHS = 3\n",
    "\n",
    "historical = model.fit(train_aug_ds, \n",
    "          steps_per_epoch=STEPS_PER_EPOCH, \n",
    "          epochs=EPOCHS, \n",
    "          validation_data=validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aadd94a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T07:29:57.829252Z",
     "iopub.status.busy": "2022-12-12T07:29:57.828528Z",
     "iopub.status.idle": "2022-12-12T08:05:16.685560Z",
     "shell.execute_reply": "2022-12-12T08:05:16.684852Z",
     "shell.execute_reply.started": "2022-12-12T06:31:56.880212Z"
    },
    "papermill": {
     "duration": 2119.928359,
     "end_time": "2022-12-12T08:05:16.685732",
     "exception": false,
     "start_time": "2022-12-12T07:29:56.757373",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "199/199 [==============================] - 379s 721ms/step - loss: 0.1210 - sparse_categorical_accuracy: 0.9637 - val_loss: 0.3486 - val_sparse_categorical_accuracy: 0.9300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 07:36:19.132052: W ./tensorflow/core/distributed_runtime/eager/destroy_tensor_handle_node.h:57] Ignoring an error encountered when deleting remote tensors handles: Invalid argument: Unable to find the relevant tensor remote_handle: Op ID: 147868, Output num: 0\n",
      "Additional GRPC error information from remote target /job:worker/replica:0/task:0:\n",
      ":{\"created\":\"@1670830579.131667899\",\"description\":\"Error received from peer ipv4:10.0.0.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Unable to find the relevant tensor remote_handle: Op ID: 147868, Output num: 0\",\"grpc_status\":3}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/15\n",
      "199/199 [==============================] - 124s 622ms/step - loss: 0.0551 - sparse_categorical_accuracy: 0.9838 - val_loss: 0.3182 - val_sparse_categorical_accuracy: 0.9353\n",
      "Epoch 3/15\n",
      "199/199 [==============================] - 123s 620ms/step - loss: 0.0399 - sparse_categorical_accuracy: 0.9879 - val_loss: 0.3100 - val_sparse_categorical_accuracy: 0.9375\n",
      "Epoch 4/15\n",
      "199/199 [==============================] - 124s 623ms/step - loss: 0.0268 - sparse_categorical_accuracy: 0.9924 - val_loss: 0.3039 - val_sparse_categorical_accuracy: 0.9388\n",
      "Epoch 5/15\n",
      "199/199 [==============================] - 124s 622ms/step - loss: 0.0215 - sparse_categorical_accuracy: 0.9947 - val_loss: 0.3049 - val_sparse_categorical_accuracy: 0.9402\n",
      "Epoch 6/15\n",
      "199/199 [==============================] - 124s 624ms/step - loss: 0.0166 - sparse_categorical_accuracy: 0.9953 - val_loss: 0.3019 - val_sparse_categorical_accuracy: 0.9413\n",
      "Epoch 7/15\n",
      "199/199 [==============================] - 124s 625ms/step - loss: 0.0163 - sparse_categorical_accuracy: 0.9965 - val_loss: 0.3023 - val_sparse_categorical_accuracy: 0.9423\n",
      "Epoch 8/15\n",
      "199/199 [==============================] - 124s 625ms/step - loss: 0.0116 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.3037 - val_sparse_categorical_accuracy: 0.9432\n",
      "Epoch 9/15\n",
      "199/199 [==============================] - 125s 628ms/step - loss: 0.0103 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.3009 - val_sparse_categorical_accuracy: 0.9432\n",
      "Epoch 10/15\n",
      "199/199 [==============================] - 125s 626ms/step - loss: 0.0092 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.3014 - val_sparse_categorical_accuracy: 0.9423\n",
      "Epoch 11/15\n",
      "199/199 [==============================] - 124s 625ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.2995 - val_sparse_categorical_accuracy: 0.9432\n",
      "Epoch 12/15\n",
      "199/199 [==============================] - 124s 625ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.3011 - val_sparse_categorical_accuracy: 0.9459\n",
      "Epoch 13/15\n",
      "199/199 [==============================] - 124s 624ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.3029 - val_sparse_categorical_accuracy: 0.9445\n",
      "Epoch 14/15\n",
      "199/199 [==============================] - 124s 625ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9991 - val_loss: 0.3010 - val_sparse_categorical_accuracy: 0.9464\n",
      "Epoch 15/15\n",
      "199/199 [==============================] - 124s 623ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9992 - val_loss: 0.3012 - val_sparse_categorical_accuracy: 0.9469\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():    \n",
    "    pretrained_model.trainable = True # fine-tuning\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Nadam(1e-5),\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "EPOCHS = 15\n",
    "\n",
    "historical = model.fit(train_aug_ds, \n",
    "          steps_per_epoch=STEPS_PER_EPOCH, \n",
    "          epochs=EPOCHS, \n",
    "          validation_data=validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "891275b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T08:05:20.502298Z",
     "iopub.status.busy": "2022-12-12T08:05:20.501573Z",
     "iopub.status.idle": "2022-12-12T08:05:20.504140Z",
     "shell.execute_reply": "2022-12-12T08:05:20.503584Z",
     "shell.execute_reply.started": "2022-12-01T09:34:25.351550Z"
    },
    "papermill": {
     "duration": 1.906162,
     "end_time": "2022-12-12T08:05:20.504291",
     "exception": false,
     "start_time": "2022-12-12T08:05:18.598129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def display_images(digits, predictions, labels, title):\n",
    "#     n = 10\n",
    "\n",
    "#     indexes = np.random.choice(len(predictions), size=n)\n",
    "#     n_digits = digits[indexes]\n",
    "#     n_predictions = predictions[indexes]\n",
    "#     n_predictions = n_predictions.reshape((n,))\n",
    "#     n_labels = labels[indexes]\n",
    " \n",
    "#     fig = plt.figure(figsize=(20, 4))\n",
    "#     plt.title(title)\n",
    "#     plt.yticks([])\n",
    "#     plt.xticks([])\n",
    "\n",
    "#     for i in range(10):\n",
    "#         ax = fig.add_subplot(1, 10, i+1)\n",
    "\n",
    "#         plt.xlabel(n_predictions[i] if n_labels[i]==n_predictions[i] else str(n_predictions[i]) + '/' + str(n_labels[i]),\n",
    "#                    color='black' if n_labels[i]==n_predictions[i] else 'red')\n",
    "#         plt.xticks([])\n",
    "#         plt.yticks([])\n",
    "#         plt.imshow(n_digits[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90aee015",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T08:05:24.387849Z",
     "iopub.status.busy": "2022-12-12T08:05:24.387137Z",
     "iopub.status.idle": "2022-12-12T08:05:24.390286Z",
     "shell.execute_reply": "2022-12-12T08:05:24.390872Z",
     "shell.execute_reply.started": "2022-12-01T09:34:27.981080Z"
    },
    "papermill": {
     "duration": 1.901209,
     "end_time": "2022-12-12T08:05:24.391060",
     "exception": false,
     "start_time": "2022-12-12T08:05:22.489851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# small_ds = list(validation_dataset.take(1).as_numpy_iterator())\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# for i, (image, label) in enumerate(zip(small_ds[0][0], small_ds[0][1])):\n",
    "#     ax = plt.subplot(3, 3, i + 1)\n",
    "#     plt.imshow(image)\n",
    "#     plt.title(int(label))\n",
    "#     plt.axis(\"off\")\n",
    "#     if i == 8:\n",
    "#         break\n",
    "\n",
    "# probabilities = model.predict(small_ds[0][0], batch_size=8)\n",
    "# probabilities = np.argmax(probabilities, axis = 1)\n",
    "\n",
    "# print(probabilities)\n",
    "# print(small_ds[0][1])\n",
    "# print(probabilities==small_ds[0][1])\n",
    "# display_images(small_ds[0][0], probabilities, small_ds[0][1], \"Bad predictions indicated in red.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116adc59",
   "metadata": {
    "papermill": {
     "duration": 1.967459,
     "end_time": "2022-12-12T08:05:28.270729",
     "exception": false,
     "start_time": "2022-12-12T08:05:26.303270",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Compute your predictions on the test set!\n",
    "\n",
    "This will create a file that can be submitted to the competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d273539a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T08:05:32.097081Z",
     "iopub.status.busy": "2022-12-12T08:05:32.096368Z",
     "iopub.status.idle": "2022-12-12T08:07:17.412739Z",
     "shell.execute_reply": "2022-12-12T08:07:17.412168Z",
     "shell.execute_reply.started": "2022-11-25T04:07:19.904272Z"
    },
    "papermill": {
     "duration": 107.231957,
     "end_time": "2022-12-12T08:07:17.412898",
     "exception": false,
     "start_time": "2022-12-12T08:05:30.180941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 08:05:32.099652: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing predictions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 08:06:45.385020: W ./tensorflow/core/distributed_runtime/eager/destroy_tensor_handle_node.h:57] Ignoring an error encountered when deleting remote tensors handles: Invalid argument: Unable to find the relevant tensor remote_handle: Op ID: 170812, Output num: 0\n",
      "Additional GRPC error information from remote target /job:worker/replica:0/task:0:\n",
      ":{\"created\":\"@1670832405.384504108\",\"description\":\"Error received from peer ipv4:10.0.0.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Unable to find the relevant tensor remote_handle: Op ID: 170812, Output num: 0\",\"grpc_status\":3}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[67 52 81 ... 14 40 79]\n",
      "Generating submission.csv file...\n"
     ]
    }
   ],
   "source": [
    "test_ds = get_test_dataset(ordered=True) # since we are splitting the dataset and iterating separately on images and ids, order matters.\n",
    "\n",
    "print('Computing predictions...')\n",
    "test_images_ds = test_ds.map(lambda image, idnum: image)\n",
    "probabilities = model.predict(test_images_ds)\n",
    "predictions = np.argmax(probabilities, axis=-1)\n",
    "print(predictions)\n",
    "\n",
    "print('Generating submission.csv file...')\n",
    "test_ids_ds = test_ds.map(lambda image, idnum: idnum).unbatch()\n",
    "test_ids = next(iter(test_ids_ds.batch(NUM_TEST_IMAGES))).numpy().astype('U') # all in one batch\n",
    "np.savetxt('submission.csv', np.rec.fromarrays([test_ids, predictions]), fmt=['%s', '%d'], delimiter=',', header='id,label', comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54bd2f3",
   "metadata": {
    "papermill": {
     "duration": 1.945285,
     "end_time": "2022-12-12T08:07:21.342712",
     "exception": false,
     "start_time": "2022-12-12T08:07:19.397427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4931.81941,
   "end_time": "2022-12-12T08:07:27.233885",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-12-12T06:45:15.414475",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
