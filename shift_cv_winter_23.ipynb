{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/pib73nl/notebookcc09c15adb?scriptVersionId=115874627\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","source":"<section \n         style=\n         \"background-image:\n          url('https://storage.googleapis.com/kaggle-competitions/kaggle/44171/logos/header.png?t=2022-12-14-02-59-05'); \n          bacground-color:DarkCyan\">\n    <div align=center style=\"line-height:70px;color:white;font-size:24px;letter-spacing:5px\">\n        <b>SHIFT CV WINTER 2023</b>\n    </div>\n    <div align=center style=\"line-height:40px;color:white;font-size:20px;letter-spacing:5px\">\n        <b>Бинарная классификация размытых изображений</b>\n    </div>\n    <hr>\n    <div align=right style=\"color:white;font-weight:400;font-size:16px;letter-spacing:2px\">\n        Выполнил: Попович И.Б.\n    </div>\n</section>","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport os\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom kaggle_datasets import KaggleDatasets\n\npd.set_option('display.max_colwidth', 200)\nprint('Tensorflow version - ', tf.__version__)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-09T04:36:11.22117Z","iopub.execute_input":"2023-01-09T04:36:11.221898Z","iopub.status.idle":"2023-01-09T04:36:19.236491Z","shell.execute_reply.started":"2023-01-09T04:36:11.221715Z","shell.execute_reply":"2023-01-09T04:36:19.235441Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2023-01-09 04:36:12.088896: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n2023-01-09 04:36:12.089043: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n","output_type":"stream"},{"name":"stdout","text":"Tensorflow version -  2.4.1\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Проблемная область","metadata":{}},{"cell_type":"markdown","source":"<p><font size='4'>Задача заключается в определении факта размытости изображения. Имеем следующие данные:\n    <ul>\n        <li>2664 тренировочных изображения, для которых известен ответ</li>\n        <li> 774 изображения для тестирования модели</li>\n    </ul>\n    Для решения задачи используем <b>TensorFlow</b>. Данные организуем в конвейер при помощи <code>tf.data.Dataset</code>. Расчет будем запускать на тензорных процессорах (<b>TPU</b>).\n    </font>\n</p> ","metadata":{}},{"cell_type":"code","source":"# для расчета используем тензорный процессор\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n    \nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n#     strategy = tf.distribute.MirroredStrategy()\n    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T04:36:19.238401Z","iopub.execute_input":"2023-01-09T04:36:19.238655Z","iopub.status.idle":"2023-01-09T04:36:24.743126Z","shell.execute_reply.started":"2023-01-09T04:36:19.238626Z","shell.execute_reply":"2023-01-09T04:36:24.742103Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Running on TPU  grpc://10.0.0.2:8470\n","output_type":"stream"},{"name":"stderr","text":"2023-01-09 04:36:19.246386: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n2023-01-09 04:36:19.249208: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n2023-01-09 04:36:19.249245: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n2023-01-09 04:36:19.249273: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (268c8d5600e8): /proc/driver/nvidia/version does not exist\n2023-01-09 04:36:19.252564: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-01-09 04:36:19.254334: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n2023-01-09 04:36:19.297057: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.0.2:8470}\n2023-01-09 04:36:19.297145: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:30020}\n2023-01-09 04:36:19.318676: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.0.2:8470}\n2023-01-09 04:36:19.318735: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:30020}\n2023-01-09 04:36:19.320596: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:411] Started server with target: grpc://localhost:30020\n","output_type":"stream"},{"name":"stdout","text":"REPLICAS:  8\n","output_type":"stream"}]},{"cell_type":"code","source":"# для тензорного процессора необходимы пути Google cloud storage\nGCS_DS_PATH = KaggleDatasets().get_gcs_path() # you can list the bucket with \"!gsutil ls $GCS_DS_PATH\"\nGCS_TRAIN_PATH = GCS_DS_PATH + '/train/train/'\nGCS_TEST_PATH = GCS_DS_PATH + '/test/test/'\nWITH_VALIDATION = False # делим датасет на train и valid (True) или все данные в train (False)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T04:36:24.74485Z","iopub.execute_input":"2023-01-09T04:36:24.745154Z","iopub.status.idle":"2023-01-09T04:36:25.152263Z","shell.execute_reply.started":"2023-01-09T04:36:24.74512Z","shell.execute_reply":"2023-01-09T04:36:25.151242Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Подготовка списка файлов для обучения","metadata":{}},{"cell_type":"code","source":"files = pd.read_csv(GCS_DS_PATH + '/train.csv', dtype={'filename': str, 'blur':np.uint8})","metadata":{"execution":{"iopub.status.busy":"2023-01-09T04:36:25.153677Z","iopub.execute_input":"2023-01-09T04:36:25.153993Z","iopub.status.idle":"2023-01-09T04:36:35.073361Z","shell.execute_reply.started":"2023-01-09T04:36:25.153957Z","shell.execute_reply":"2023-01-09T04:36:35.072215Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# в датасете 2664 изображения, поделенные на два класса; классы сбалансированы почти поровну\nprint(files.info())\nprint(files.describe())","metadata":{"execution":{"iopub.status.busy":"2023-01-09T04:36:35.075817Z","iopub.execute_input":"2023-01-09T04:36:35.076067Z","iopub.status.idle":"2023-01-09T04:36:35.11677Z","shell.execute_reply.started":"2023-01-09T04:36:35.076038Z","shell.execute_reply":"2023-01-09T04:36:35.115803Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 2664 entries, 0 to 2663\nData columns (total 2 columns):\n #   Column    Non-Null Count  Dtype \n---  ------    --------------  ----- \n 0   filename  2664 non-null   object\n 1   blur      2664 non-null   uint8 \ndtypes: object(1), uint8(1)\nmemory usage: 23.5+ KB\nNone\n              blur\ncount  2664.000000\nmean      0.486862\nstd       0.499921\nmin       0.000000\n25%       0.000000\n50%       0.000000\n75%       1.000000\nmax       1.000000\n","output_type":"stream"}]},{"cell_type":"code","source":"# добавим gcs-пути к именам файлов\nfiles['filename'] = files['filename'].apply(lambda x: GCS_TRAIN_PATH + str(x))","metadata":{"execution":{"iopub.status.busy":"2023-01-09T04:36:35.11833Z","iopub.execute_input":"2023-01-09T04:36:35.118634Z","iopub.status.idle":"2023-01-09T04:36:35.127067Z","shell.execute_reply.started":"2023-01-09T04:36:35.118598Z","shell.execute_reply":"2023-01-09T04:36:35.125903Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"files.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-09T04:36:35.128718Z","iopub.execute_input":"2023-01-09T04:36:35.12903Z","iopub.status.idle":"2023-01-09T04:36:35.154425Z","shell.execute_reply.started":"2023-01-09T04:36:35.128996Z","shell.execute_reply":"2023-01-09T04:36:35.153273Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                                                                                 filename  \\\n0  gs://kds-70c503abd5ae4b2998787cd4483fa2b113153fe0d5c7446f5deb9ffe/train/train/kagouracdzwrjjxzzedi.jpg   \n1  gs://kds-70c503abd5ae4b2998787cd4483fa2b113153fe0d5c7446f5deb9ffe/train/train/ahnamimqdfqoqdnozabc.jpg   \n2  gs://kds-70c503abd5ae4b2998787cd4483fa2b113153fe0d5c7446f5deb9ffe/train/train/gwhdadvghuzinmzhzssx.jpg   \n3  gs://kds-70c503abd5ae4b2998787cd4483fa2b113153fe0d5c7446f5deb9ffe/train/train/onqwabwwckubrydgbzly.jpg   \n4  gs://kds-70c503abd5ae4b2998787cd4483fa2b113153fe0d5c7446f5deb9ffe/train/train/ewpqdruddbokqyzzupcw.jpg   \n\n   blur  \n0     0  \n1     0  \n2     0  \n3     0  \n4     1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>blur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>gs://kds-70c503abd5ae4b2998787cd4483fa2b113153fe0d5c7446f5deb9ffe/train/train/kagouracdzwrjjxzzedi.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>gs://kds-70c503abd5ae4b2998787cd4483fa2b113153fe0d5c7446f5deb9ffe/train/train/ahnamimqdfqoqdnozabc.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>gs://kds-70c503abd5ae4b2998787cd4483fa2b113153fe0d5c7446f5deb9ffe/train/train/gwhdadvghuzinmzhzssx.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>gs://kds-70c503abd5ae4b2998787cd4483fa2b113153fe0d5c7446f5deb9ffe/train/train/onqwabwwckubrydgbzly.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>gs://kds-70c503abd5ae4b2998787cd4483fa2b113153fe0d5c7446f5deb9ffe/train/train/ewpqdruddbokqyzzupcw.jpg</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"label = files.pop('blur') # метки в отдельный фатафрейм","metadata":{"execution":{"iopub.status.busy":"2023-01-09T04:36:35.156058Z","iopub.execute_input":"2023-01-09T04:36:35.156502Z","iopub.status.idle":"2023-01-09T04:36:35.162751Z","shell.execute_reply.started":"2023-01-09T04:36:35.156463Z","shell.execute_reply":"2023-01-09T04:36:35.161954Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# если просили валидацию - делим\nif WITH_VALIDATION:\n    X_train, X_val, y_train, y_val = train_test_split(files, label, test_size = 0.05, random_state=42, stratify=label)\nelse:\n    X_train = files\n    y_train = label","metadata":{"execution":{"iopub.status.busy":"2023-01-09T04:36:35.164415Z","iopub.execute_input":"2023-01-09T04:36:35.164944Z","iopub.status.idle":"2023-01-09T04:36:35.179285Z","shell.execute_reply.started":"2023-01-09T04:36:35.164906Z","shell.execute_reply":"2023-01-09T04:36:35.178075Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"IMAGE_SIZE = [640, 640]\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync\n\nNUM_TRAINING_IMAGES = X_train.shape[0]*2 # в двойном размере, т.к. каждое изображение еще аугментируем\nSTEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE","metadata":{"execution":{"iopub.status.busy":"2023-01-09T04:36:35.181279Z","iopub.execute_input":"2023-01-09T04:36:35.181636Z","iopub.status.idle":"2023-01-09T04:36:35.195624Z","shell.execute_reply.started":"2023-01-09T04:36:35.181595Z","shell.execute_reply":"2023-01-09T04:36:35.19435Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Подготовка конвейеров данных","metadata":{}},{"cell_type":"code","source":"def decode_image(*image_data):\n    \"\"\"\n    Декодирует изображение\n    \n    Параметры:\n     image_data: tuple (2); первый элемент - путь к файлу, второй - метка \n                 (ground truth для train и valid, имя файла для test)\n    Возврат:\n     image: тензор [*IMAGE_SIZE, 3] пикселей изображения, отображенный на интервал [0,1]\n     label: метка изображения (ground truth для train и valid, имя файла для test)\n    \"\"\"\n    \n    image_path, label = image_data\n    image = tf.io.read_file(tf.squeeze(image_path))\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0  \n    image = tf.reshape(image, [*IMAGE_SIZE, 3]) \n\n    return image, label\n\ndef decode_image_augm(*image_data):\n    \"\"\"\n    Вносит некоторые изменения в изображение (аугментация)\n    \n    Параметры:\n     image_data: tuple (2); первый элемент - путь к файлу, второй - метка \n                 (ground truth для train и valid, имя файла для test)\n    Возврат:\n     image: тензор [*IMAGE_SIZE, 3] пикселей изображения, отображенный на интервал [0,1]\n     label: метка изображения (ground truth для train и valid, имя файла для test)\n    \"\"\"\n    # на вм с TPU стоит версия tensorflow 2.4.1, поэтому аугментируем как-то так...\n    image, label = decode_image(*image_data)\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_contrast(image, 0.7, 1.5)\n    image = tf.image.random_brightness(image, 0.3)\n    image = tf.image.rot90(image, np.random.randint(1,4))\n    return image, label\n\n\ndef load_dataset(filenames, labels, augmentation=False):\n    \"\"\"\n    Готовит датасет из путей к файлам и меток, и маппирует на него функции декодирования изображений\n    \n    Параметры:\n     filenames:    список путей к файлам\n     labels:       список меток (ground truth для train и valid, имя файла для test)\n     augmentation: признак применения аугментации (default - False)\n    Возврат:\n     dataset:      датасет (image, label)\n    \"\"\"\n    \n    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n\n    dataset = dataset.map(decode_image_augm if augmentation else decode_image,\n                          num_parallel_calls=tf.data.AUTOTUNE)\n    \n    return dataset\n\ndef get_dataset(filenames, labels, type_ds: ('train', 'valid', 'test') = 'train', augmentation=False):\n    \"\"\"\n    Подготовка конвейеров\n    \n    Параметры:\n     filenames:    список путей к файлам\n     labels:       список меток (ground truth для train и valid, имя файла для test)\n     type_ds:      тип датасета (один из вариантов: 'train', 'valid', 'test')\n     augmentation: признак применения аугментации (default - False)\n    Возврат:\n     dataset:      датасет (image, label)\n    \"\"\"\n    assert type_ds in get_dataset.__annotations__['type_ds']\n    \n    dataset = load_dataset(filenames, labels, augmentation=augmentation)\n    \n    if type_ds == 'train':\n        dataset = dataset.repeat() # the training dataset must repeat for several epochs\n        dataset = dataset.shuffle(2048)\n    \n    dataset = dataset.batch(BATCH_SIZE)\n    \n    if type_ds == 'valid':\n        dataset = dataset.cache()\n    \n    return dataset","metadata":{"execution":{"iopub.status.busy":"2023-01-09T04:36:35.197311Z","iopub.execute_input":"2023-01-09T04:36:35.197672Z","iopub.status.idle":"2023-01-09T04:36:35.21259Z","shell.execute_reply.started":"2023-01-09T04:36:35.197629Z","shell.execute_reply":"2023-01-09T04:36:35.21152Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# готовим конвейеры для train-а\ntraining_dataset = get_dataset(X_train, y_train, 'train') # оригинальные изображения\naugmented_dataset = get_dataset(X_train, y_train, 'train', augmentation=True) # аугментированные изображения\ntraining_dataset = training_dataset.concatenate(augmented_dataset)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T04:36:35.214142Z","iopub.execute_input":"2023-01-09T04:36:35.214666Z","iopub.status.idle":"2023-01-09T04:36:35.528962Z","shell.execute_reply.started":"2023-01-09T04:36:35.21463Z","shell.execute_reply":"2023-01-09T04:36:35.527521Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# ... и для валидации, если заказана\nif WITH_VALIDATION:\n    validation_dataset = get_dataset(X_val, y_val, 'valid') # оригинальные изображения\n    augmented_dataset = get_dataset(X_val, y_val, 'valid', augmentation=True) # аугментированные изображения\n    validation_dataset = validation_dataset.concatenate(augmented_dataset)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T04:36:35.531678Z","iopub.execute_input":"2023-01-09T04:36:35.532337Z","iopub.status.idle":"2023-01-09T04:36:35.539051Z","shell.execute_reply.started":"2023-01-09T04:36:35.532277Z","shell.execute_reply":"2023-01-09T04:36:35.537935Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## Обучение модели","metadata":{}},{"cell_type":"code","source":"EPOCHS = 20\n\n# организуем распределенное обучение на TPU\nwith strategy.scope():    \n    pretrained_model = tf.keras.applications.DenseNet201(weights='imagenet', include_top=False ,input_shape=[*IMAGE_SIZE, 3])\n    pretrained_model.trainable = False # обучение пока отключим\n    \n    # добавим немного слоев...\n    model = tf.keras.Sequential([\n        pretrained_model,\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.Dropout(0.2),\n        tf.keras.layers.Dense(1024, activation='relu'),\n        tf.keras.layers.Dropout(0.2),\n        tf.keras.layers.Dense(512, activation='relu'),\n        tf.keras.layers.Dropout(0.2),\n        tf.keras.layers.Dense(256, activation='relu'),\n        tf.keras.layers.Dropout(0.2),\n        tf.keras.layers.Dense(1, activation='sigmoid')\n    ])\n    \n    # метрика в соревновании AUC_ROC\n    auc_roc = tf.keras.metrics.AUC()\n        \nmodel.compile(\n#     optimizer='adam',\n    optimizer=tf.keras.optimizers.Nadam(),\n    loss = 'binary_crossentropy',\n    metrics=auc_roc\n)\n\nhistorical = model.fit(training_dataset, \n          steps_per_epoch=STEPS_PER_EPOCH, \n          epochs=EPOCHS, \n          validation_data=validation_dataset if WITH_VALIDATION else None)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T04:36:35.542243Z","iopub.execute_input":"2023-01-09T04:36:35.542526Z","iopub.status.idle":"2023-01-09T05:18:27.263973Z","shell.execute_reply.started":"2023-01-09T04:36:35.542473Z","shell.execute_reply":"2023-01-09T05:18:27.262887Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n74842112/74836368 [==============================] - 0s 0us/step\nEpoch 1/20\n41/41 [==============================] - 216s 3s/step - loss: 0.6832 - auc: 0.6582\nEpoch 2/20\n41/41 [==============================] - 121s 3s/step - loss: 0.3624 - auc: 0.9156\nEpoch 3/20\n41/41 [==============================] - 116s 3s/step - loss: 0.2108 - auc: 0.9696\nEpoch 4/20\n41/41 [==============================] - 118s 3s/step - loss: 0.2225 - auc: 0.9686\nEpoch 5/20\n41/41 [==============================] - 118s 3s/step - loss: 0.1578 - auc: 0.9807\nEpoch 6/20\n41/41 [==============================] - 126s 3s/step - loss: 0.1500 - auc: 0.9848\nEpoch 7/20\n41/41 [==============================] - 115s 3s/step - loss: 0.1416 - auc: 0.9860\nEpoch 8/20\n41/41 [==============================] - 117s 3s/step - loss: 0.1109 - auc: 0.9913\nEpoch 9/20\n41/41 [==============================] - 114s 3s/step - loss: 0.1247 - auc: 0.9884\nEpoch 10/20\n41/41 [==============================] - 117s 3s/step - loss: 0.1096 - auc: 0.9913\nEpoch 11/20\n41/41 [==============================] - 120s 3s/step - loss: 0.1915 - auc: 0.9772\nEpoch 12/20\n41/41 [==============================] - 118s 3s/step - loss: 0.1063 - auc: 0.9917\nEpoch 13/20\n41/41 [==============================] - 117s 3s/step - loss: 0.1057 - auc: 0.9921\nEpoch 14/20\n41/41 [==============================] - 118s 3s/step - loss: 0.0860 - auc: 0.9939\nEpoch 15/20\n41/41 [==============================] - 120s 3s/step - loss: 0.1151 - auc: 0.9909\nEpoch 16/20\n41/41 [==============================] - 119s 3s/step - loss: 0.0803 - auc: 0.9954\nEpoch 17/20\n41/41 [==============================] - 118s 3s/step - loss: 0.0965 - auc: 0.9924\nEpoch 18/20\n41/41 [==============================] - 120s 3s/step - loss: 0.0948 - auc: 0.9941\nEpoch 19/20\n41/41 [==============================] - 117s 3s/step - loss: 0.0637 - auc: 0.9968\nEpoch 20/20\n41/41 [==============================] - 122s 3s/step - loss: 0.0686 - auc: 0.9967\n","output_type":"stream"}]},{"cell_type":"code","source":"with strategy.scope():    \n    pretrained_model.trainable = True # немного \"расшатаем\" модель (эмпирическое наблюдение - иногда очень помогает :)\n\nmodel.compile(\n    optimizer=tf.keras.optimizers.Nadam(),\n    loss = 'binary_crossentropy',\n    metrics=auc_roc)\n    \nEPOCHS = 3\n\nhistorical = model.fit(training_dataset, \n          steps_per_epoch=STEPS_PER_EPOCH, \n          epochs=EPOCHS, \n          validation_data=validation_dataset if WITH_VALIDATION else None)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T05:18:27.265819Z","iopub.execute_input":"2023-01-09T05:18:27.266108Z","iopub.status.idle":"2023-01-09T05:29:20.379587Z","shell.execute_reply.started":"2023-01-09T05:18:27.266075Z","shell.execute_reply":"2023-01-09T05:29:20.378417Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Epoch 1/3\n41/41 [==============================] - 406s 3s/step - loss: 0.8716 - auc: 0.9763\nEpoch 2/3\n41/41 [==============================] - 118s 3s/step - loss: 0.1059 - auc: 0.9927\nEpoch 3/3\n41/41 [==============================] - 120s 3s/step - loss: 0.1215 - auc: 0.9904\n","output_type":"stream"}]},{"cell_type":"code","source":"model.compile(\n    optimizer=tf.keras.optimizers.Nadam(1e-5), # делаем fine-tuning с низким learning rate\n    loss = 'binary_crossentropy',\n    metrics=auc_roc)\n\nEPOCHS = 10\n\nhistorical = model.fit(training_dataset, \n          steps_per_epoch=STEPS_PER_EPOCH, \n          epochs=EPOCHS, \n          validation_data=validation_dataset if WITH_VALIDATION else None)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T05:29:20.381917Z","iopub.execute_input":"2023-01-09T05:29:20.382427Z","iopub.status.idle":"2023-01-09T05:54:09.874985Z","shell.execute_reply.started":"2023-01-09T05:29:20.382323Z","shell.execute_reply":"2023-01-09T05:54:09.873742Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Epoch 1/10\n41/41 [==============================] - 416s 3s/step - loss: 0.0416 - auc: 0.9947\nEpoch 2/10\n41/41 [==============================] - 122s 3s/step - loss: 0.0173 - auc: 0.9998\nEpoch 3/10\n41/41 [==============================] - 117s 3s/step - loss: 0.0138 - auc: 0.9995\nEpoch 4/10\n41/41 [==============================] - 118s 3s/step - loss: 0.0160 - auc: 0.9995\nEpoch 5/10\n41/41 [==============================] - 119s 3s/step - loss: 0.0086 - auc: 1.0000\nEpoch 6/10\n41/41 [==============================] - 120s 3s/step - loss: 0.0083 - auc: 1.0000\nEpoch 7/10\n41/41 [==============================] - 115s 3s/step - loss: 0.0086 - auc: 0.9993\nEpoch 8/10\n41/41 [==============================] - 120s 3s/step - loss: 0.0119 - auc: 0.9998\nEpoch 9/10\n41/41 [==============================] - 115s 3s/step - loss: 0.0063 - auc: 1.0000\nEpoch 10/10\n41/41 [==============================] - 115s 3s/step - loss: 0.0053 - auc: 1.0000\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Prediction and submission","metadata":{}},{"cell_type":"code","source":"# готовим конвейер для test-а\ntest_files_path = tf.io.gfile.glob(GCS_TEST_PATH + '*.jpg')\ntest_files_list = [os.path.split(path)[1] for path in test_files_path]\ntest_dataset = get_dataset(test_files_path, test_files_list, 'test')","metadata":{"execution":{"iopub.status.busy":"2023-01-09T05:54:09.877021Z","iopub.execute_input":"2023-01-09T05:54:09.877314Z","iopub.status.idle":"2023-01-09T05:54:18.051087Z","shell.execute_reply.started":"2023-01-09T05:54:09.877281Z","shell.execute_reply":"2023-01-09T05:54:18.049895Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"2023-01-09 05:54:09.886980: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n","output_type":"stream"}]},{"cell_type":"code","source":"NUM_TEST_IMAGES = len(test_files_list)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T05:54:18.053243Z","iopub.execute_input":"2023-01-09T05:54:18.053654Z","iopub.status.idle":"2023-01-09T05:54:18.058802Z","shell.execute_reply.started":"2023-01-09T05:54:18.053613Z","shell.execute_reply":"2023-01-09T05:54:18.057929Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"%%time\n# предсказание и подготовка submission.csv\nprint('Computing predictions...')\ntest_images_ds = test_dataset.map(lambda image, filename: image, num_parallel_calls=tf.data.AUTOTUNE)\npredictions = model.predict(test_images_ds)\n\nprint('Generating submission.csv file...')\ntest_ids_ds = test_dataset.map(lambda image, filename: filename, num_parallel_calls=tf.data.AUTOTUNE).unbatch()\ntest_ids = next(iter(test_ids_ds.batch(NUM_TEST_IMAGES))).numpy().astype('U') # all in one batch\nnp.savetxt('submission.csv', np.rec.fromarrays([test_ids, np.squeeze(predictions)]), \n           fmt=['%s', '%.5f'], delimiter=',', header='filename,blur', comments='')","metadata":{"execution":{"iopub.status.busy":"2023-01-09T05:54:18.060005Z","iopub.execute_input":"2023-01-09T05:54:18.060413Z","iopub.status.idle":"2023-01-09T05:55:24.520367Z","shell.execute_reply.started":"2023-01-09T05:54:18.060359Z","shell.execute_reply":"2023-01-09T05:55:24.519385Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Computing predictions...\nWARNING: AutoGraph could not transform <function <lambda> at 0x7f99b2543560> and will run it as-is.\nCause: could not parse the source code of <function <lambda> at 0x7f99b2543560>: no matching AST found\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\nGenerating submission.csv file...\nWARNING: AutoGraph could not transform <function <lambda> at 0x7f9990ed8830> and will run it as-is.\nCause: could not parse the source code of <function <lambda> at 0x7f9990ed8830>: no matching AST found\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\nCPU times: user 5.51 s, sys: 337 ms, total: 5.85 s\nWall time: 1min 6s\n","output_type":"stream"}]}]}